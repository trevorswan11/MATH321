\documentclass[12pt]{article}

% Custom Commands
\newcommand{\set}[1]{\left\{ {#1} \right\}}
\newcommand{\limit}[1]{\displaystyle \lim_{ {#1} }}
\newcommand{\limtoinf}[1][n]{\displaystyle\lim_{ {#1} \to \infty}}
\newcommand{\liminftoinf}[1][n]{\displaystyle\liminf_{ {#1} \to \infty}}
\newcommand{\limsuptoinf}[1][n]{\displaystyle\limsup_{ {#1} \to \infty}}
\newcommand{\abs}[1]{\left| {#1} \right|}
\newcommand{\ceil}[1]{\lceil {#1} \rceil}
\newcommand{\floor}[1]{\lfloor {#1} \rfloor}
\newcommand{\seq}[2][n]{\left\{ {#2} \right\}_{#1=1}^\infty}
\newcommand{\paren}[1]{\left( {#1} \right)}
\newcommand{\series}[2]{\displaystyle \sum_{ {#1} }^{ {#2} }}
\newcommand{\bR}{\mathbb{R}}
\newcommand{\bZ}{\mathbb{Z}}
\newcommand{\bN}{\mathbb{N}}
\newcommand{\bQ}{\mathbb{Q}}

% Math and symbol packages
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{derivative}

% Formatting
\usepackage{inputenc}
\usepackage[left=2.54cm,right=2.54cm,top=2.54cm,bottom=2.54cm]{geometry}
\usepackage{fancyhdr}
\usepackage{lipsum}

% Spacing formats
\AtBeginDocument{
	\setlength{\abovedisplayskip}{-2pt}
	\setlength{\belowdisplayskip}{5pt}
}

% Actual content
\begin{document}
\pagestyle{fancy}
\setlength{\headheight}{14.49998pt}
\fancyhead[L]{Trevor Swan}
\fancyhead[C]{\textbf{MATH321 - HW6}}
\fancyhead[R]{10/11/24}
\fancyfoot[C]{\thepage}

% Begin Problem 1
\noindent \textbf{(2.5.2)} Prove \underline{Proposition 2.5.5}, that is, for $-1<r<1$, prove

\begin{align*}
	\series{n=0}{\infty}r^n=\frac{1}{1-r}
\end{align*}

\noindent given that the geometric series $\series{n=0}{\infty}r^n$ converges.

\begin{proof}
	Let $S_k$ be the partial sum of the series up to the $k$-th term of the series, that is $S_k=\sum{n=0}{\infty}=1+r+r^2+\dots+r^k$. We must first show that $S_k=\frac{1-r^{k+1}}{1-r}$ for a finite $k$ and $r\neq1$. For the base case, take $k=0$ so $S_0=1$ and the formula gives $S_0=\frac{1-r^1}{1-r}=1$, so this holds for $k=0$. Assume this holds for some $k$, so $S_k=1+r+r^2+\dots+r^k=\frac{1-r^{k+1}}{1-r}$. We must show that this holds for $k+1$, or that $S_{k+1}=1+r+r^2+\dots+r^{k+1}=\frac{1-r^{k+2}}{1-r}$. Notice that $S_{k+1}=S_k+r^{k+1}$, so we have $S_{k+1}=\frac{1-r^{k+1}}{1-r}+r^{k+1}$. We can then simply this expression as
	
\begin{align*}
	S_{k+1}=&\frac{1-r^{k+1}}{1-r}+\frac{(1-r)r^{k+1}}{1-r} && \text{Common denominator} \\
	=&\frac{1-r^{k+1}+r^{k+1}-r^{k+2}}{1-r} && \text{Expand the second term} \\
	=& \frac{1-r^{k+2}}{1-r} && \text{as required}
\end{align*}

This proves that the partial sums $S_k=\frac{1-r^{k+1}}{1-r}$. If we take the limit of the partial sums as $k\to\infty$, we can use the fact that since $-1<r<1$, $\limtoinf[k]r^{k+1}=0$. Therefore we have that

\begin{align*}
	\limtoinf[k]S_k=&\limtoinf[k]\frac{1-r^{k+1}}{1-r} \\
	=& \frac{1}{1-r}\cdot\limtoinf[k]\paren{1-r^{k+1}} && \text{Factor out scalar} \\
	=& \frac{1}{1-r}\paren{1- \limtoinf[k]r^{k+1}} && \text{Limit algebra} \\ 
	=& \frac{1}{1-r}\cdot\paren{1-0} && \text{Use }\limtoinf[k]r^{k+1}=0
\end{align*}

Thus showing that as the number of terms in the partial sums tends to $\infty$, we have that $\limtoinf[k]S_k=\series{n=0}{\infty}r^n=\frac{1}{1-r}$. Hence given $-1<r<1$, $\series{n=0}{\infty}r^n$ converges to $\frac{1}{1-r}$, as required.
\end{proof}

\newpage

% Begin Problem 2
\noindent \textbf{(2.5.3)} Decide the convergence or divergence of the following series.

\noindent (a) $\series{n=1}{\infty}\frac{3}{9n+1}$

\begin{proof}
	First, notice that $\frac{3}{9n+1}>0$ for all $n\in\bN$. We will compare this to $\frac{1}{n}$, which is also positive for all $n$. We can use the limit comparison test as follows
	
\begin{align*}
	\limtoinf\frac{\frac{3}{9n+1}}{\frac{1}{n}}=\limtoinf\frac{3n}{9n+1}=\limtoinf\frac{3}{9+\frac{1}{n}}=\frac{3}{9}
\end{align*}

Note that the last equality holds as $\limtoinf\frac{1}{n}=0$. Since we have used the limit comparison test to compare $\series{n=1}{\infty}\frac{1}{n}$ and $\series{n=1}{\infty}\frac{3}{9n+1}$, we have shown that $\series{n=1}{\infty}\frac{3}{9n+1}$ diverges as $\series{n=1}{\infty}\frac{1}{n}$ diverges and both series must either both converge or diverge if $0<\limtoinf\frac{a_n}{b_n}<\infty$.
\end{proof}


\noindent (b) $\series{n=1}{\infty}\frac{1}{2n-1}$

\begin{proof}
	Notice again that $\frac{1}{2n-1}>0$ for all $n\in\bN$. We will compare this to $\frac{1}{n}$, which is also positive for all $n$. We can use the limit comparison test as follows
	
\begin{align*}
	\limtoinf\frac{\frac{1}{2n-1}}{\frac{1}{n}}=\limtoinf\frac{n}{2n-1}=\limtoinf\frac{1}{2-\frac{1}{n}}=\frac{1}{2}
\end{align*}

Since we have used the limit comparison test to compare $\series{n=1}{\infty}\frac{1}{n}$ and $\series{n=1}{\infty}\frac{1}{2n-1}$, we have shown that the series diverges as $\series{n=1}{\infty}\frac{1}{n}$ diverges as $\frac{1}{2}$ is a positive constant.
\end{proof}

\noindent (c) $\series{n=1}{\infty}\frac{(-1)^n}{n^2}$

\begin{proof}
	We will prove this using the alternating series test, which is proved on \underline{J. Lebl pp.101}. The test states that if $\seq{x_n}$ is a monotone decreasing sequence of positive real number such that $\limtoinf x_n=0$, then $\series{n=1}{\infty}(-1)^nx_n$ converges. We must show, therefore, that given $x_n=\frac{1}{n^2},$ $\seq{x_n}$ is a monotone decreasing sequence where $x_n\ge 0$ for all $n\in\bN$ and that $\limtoinf\frac{1}{n^2}=0$. 
	
	Firstly, note that $\frac{1}{n^2}\ge0$ for all $n\in\bN$ as $n^2\ge0$. Next, we define $x_{n+1}=\frac{1}{(n+1)^2}$, and we know that $n^2\le(n+1)^2$ for all $n$ and hence $\frac{1}{n^2}\ge\frac{1}{(n+1)^2}$. Therefore $x_n\ge x_{n+1}$ so we have shown that $x_n$ is monotone decreasing and positive for all $n$. We can formally write that $x_n$ is monotone decreasing and bounded below by zero, so $\inf x_n = 0$, and hence the MCT tells us that $\limtoinf x_n=\limtoinf\frac{1}{n^2}=0$. Therefore as $\limtoinf\frac{1}{n^2}=0$ and $\frac{1}{n^2}$ is monotone decreasing, the series $\series{n=1}{\infty}\frac{(-1)^n}{n^2}$ converges.
\end{proof}

\noindent (d) $\series{n=1}{\infty}\frac{1}{n(n+1)}$

\begin{proof}
	First note that $\frac{1}{n}-\frac{1}{n+1}=\frac{1}{n(n+1)}$. This can be supported by
	
\begin{align*}
	\frac{1}{n}-\frac{1}{n+1}=\frac{(n+1)}{n(n+1)}-\frac{n}{n(n+1)}=\frac{(n+1)-n}{n(n+1)}=\frac{1}{n(n+1)}
\end{align*}

\noindent Hence we can express the series $\series{n=1}{\infty}\frac{1}{n(n+1)}$ as the telescoping sum

\begin{align*}
	\series{n=1}{\infty}\frac{1}{n(n+1)}=&\series{n=1}{\infty}\frac{1}{n}-\series{n=1}{\infty}\frac{1}{n+1} \\
	=&\paren{1-\frac{1}{2}}+\paren{\frac{1}{2}-\frac{1}{3}}+\paren{\frac{1}{3}-\frac{1}{4}}+\dots && \text{Write out the first few terms} \\
	=&1 && \text{All terms after 1 cancel out}
\end{align*}

	Therefore the series $\series{n=1}{\infty}\frac{1}{n(n+1)}$ converges as it is a telescoping series and more specifically converges to 1.

\end{proof}

\noindent (e) $\series{n=1}{\infty}ne^{-n^2}$

\begin{proof}
	We will choose to compare the series $\series{n=1}{\infty}\frac{n}{e^{n^2}}$ to $\series{n=1}{\infty}\frac{n}{n^3}$. First note that both $ne^{-n^2}$ and $\frac{n}{n^3}$ are positive for all $n\in\bN$. To justify this choice and , compare $e^{n^2}$ to $n^3$ (continuous functions) as
	
\begin{align*}
	\limtoinf\frac{e^{n^2}}{n^3}\overset{LH}{=}\limtoinf\frac{\frac{d}{dn}e^{n^2}}{\frac{d}{dn}n^3}=\limtoinf\frac{2ne^{n^2}}{3n}\to\infty \qquad \paren{\frac{\text{Exponential}}{\text{Linear}}\to\infty}.
\end{align*}

The limit of the terms tends to infinity showing that $e^{n^2}\ge n^3$ and hence $\frac{1}{e^{n^2}}\le\frac{1}{n^3}$. Consequently we have that $\series{n=1}{\infty}ne^{-n^2}\le\series{n=1}{\infty}\frac{n}{n^3}=\series{n=1}{\infty}\frac{1}{n^2},$ and $\series{n=1}{\infty}\frac{1}{n^2}$ converges by the p-series test with $p=2$. In summary we have shown that $0\le\series{n=1}{\infty}ne^{-n^2}\le\frac{1}{n^2}$. Therefore by the comparison test, $\series{n=1}{\infty}ne^{-n^2}$ converges.
\end{proof}

\newpage

% Begin Problem 3
\noindent \textbf{(2.5.14)} Suppose $\series{n=1}{\infty}x_n$ converges and $x_n\ge0$ for all $n$. Prove that $\series{n=1}{\infty} x_n^2$ converges.

\begin{proof}
	To determine the convergence of $\series{n=1}{\infty} x_n^2$, we can compare it to $\series{n=1}{\infty}x_n$. Because  $\series{n=1}{\infty}x_n$ is convergent, it implies the as $n$ gets sufficiently large, $x_n\to0$. In other words, the convergence of  $\series{n=1}{\infty}x_n$ implies that $\limtoinf x_n=0$. Therefore we have that $0<x<1$ for sufficiently large $n$. Notice that for $\series{n=1}{\infty} x_n^2$, we have $x_n^2\le x_n$ for sufficiently large $n$. Note that we have to prove this expression, and also that we only care about long term behavior as that is what ultimately determines convergence. We therefore have
	
\begin{align*}
	x^2\le&x&&\text{Want to show for }0<x<1 \\
	x - x^2\ge&0&&\text{Subtract }x\text{ from both sides} \\
	x(1-x)\ge&0&&\text{Factor the expression}
\end{align*} 

The following statement is true as $0<x<1$ is given and hence $x$ and $1-x$, the factors, are both always positive. Therefore $x^2\le x$ holds for all $0<x<1$.

Let $M\in\bN$ be given such that $n\ge M$, thus we are comparing the tails of the series when $0<x<1$ holds. We therefore have that $0\le x_n^2\le x_n$ for all $n\ge M$. Note that $\series{n=1}{\infty}x_n$ converges for $n\ge M$ as a series converges if and only if its tails converge. This also means that if a series tails converge, then the series also converges. Since $\series{n=1}{\infty}x_n$ converges and the terms in the long term bound the terms of $\sum x_n^2$, $\series{n=1}{\infty} x_n^2$  must also converge by the comparison test.
\end{proof}

\newpage

% Begin Problem 4
\noindent \textbf{(3.1.1)} Find the limit (and prove it of course) or prove that the limit does not exist.

\noindent (a) $\limit{x\to c} \sqrt{x}$, for $c\ge0$

\begin{proof}
	Assume $f(x)=\sqrt{x}$ and $f:S\to\bR$ where $S=[0,\infty\}$. We will suggest that as the square root is a continuous function, $L=\sqrt{c}$. Therefore we must show that for every $\epsilon>0$, there exists some $\delta>0$ for which $\abs{f(x)-L}=\abs{\sqrt{x}-\sqrt{c}}<\epsilon$ holds whenever $x\in S\setminus\set{c}$ satisfies $\abs{x-c}<\delta$. 
	
We can multiply $\abs{\sqrt{x}-\sqrt{c}}$ by its conjugate to get $\abs{\sqrt{x}-\sqrt{c}}=\frac{\abs{x-c}}{\abs{\sqrt{x}+\sqrt{c}}}$. Note that since $\sqrt{x}$ and $\sqrt{c}$ are both always positive, we can ignore the absolute value of its sum and can further say that $\sqrt{x}+\sqrt{c}\ge\sqrt{c}$. Consequently $\frac{1}{\sqrt{x}+\sqrt{c}}\le\frac{1}{\sqrt{c}}$, leading us to $\abs{\sqrt{x}-\sqrt{c}}\le\frac{\abs{x-c}}{\sqrt{c}}$. To ensure the inequality $\abs{\sqrt{x}-\sqrt{c}}<\epsilon$ is satisfied, we need $\frac{\abs{x-c}}{\sqrt{c}}<\epsilon$ to hold as it bounds $\abs{\sqrt{x}-\sqrt{c}}$. This gives us $\abs{x-c}<\epsilon\sqrt{c}$ and thus we choose $\delta=\epsilon\sqrt{c}$. Note that for $c=0$, we have $\abs{\sqrt{x}-0}=\sqrt{x}$ and to ensure $\sqrt{x}<\epsilon$, we need $x<\epsilon^2$. Hence we can choose $\delta=\epsilon^2$ to guarantee that for $x<\delta$, we have $\sqrt{x}<\epsilon$. Therefore $\limit{x\to c} \sqrt{x}=c$, as required.
\end{proof}

\noindent (b) $\limit{x\to c}x^2 + x + 1$, for $c\in\bR$

\begin{proof}
	Let $f(x)=x^2+x+1$, and we want to show that for every $\epsilon>0$, there exists a $\delta>0$ such that whenever $\abs{x-c}<\delta$, it holds that 
	
\begin{align*}
	\abs{f(x)-f(c)}=\abs{(x^2+x+1)-(c^2+c+1)}=&\abs{x^2-c^2+x-c} \\
	=&\abs{(x-c)(x+c)+(x-c)} \\
	=&\abs{x-c}\cdot\abs{x+c+1} <\epsilon
\end{align*}

Note that we can rewrite $\abs{x+c+1}=\abs{(x-c)+(2c+1)}$, and by the triangle inequality we have $\abs{(x-c)+(2c+1)}\le\abs{x-c}+\abs{2c+1}$. As $\abs{x-c}<\delta$, we have $\abs{x+c+1}\le\abs{2c+1}+\delta$. Consequently we can write $\abs{x-c}\cdot\abs{x+c+1}\le\abs{x-c}\cdot\paren{\abs{2c+1}+\delta}<\epsilon$, and hence we need to fulfill $\abs{x-c}\cdot\paren{\abs{2c+1}+\delta}<\epsilon$. Choose $\delta=\min\paren{1,\frac{\epsilon}{\abs{2c+1}+1}}$. This choice ensures that $\abs{x-c}$ is kept sufficiently small and that the product $\abs{x-c}\cdot\paren{\abs{2c+1}+\delta}$ is less than $\epsilon$. Thus $\limit{x\to c}x^2 + x + 1=c^2+c+1$ as required.
\end{proof}

\noindent (c) $\limit{x\to0}x^2\cos\paren{\frac{1}{x}}$

\begin{proof}
	Let $f(x)=x^2\cos\paren{\frac{1}{x}}$. We will use the squeeze theorem to prove its limit. First note that the cosine function is bounded by 1, meaning that $\abs{\cos n}\le 1$, where $n=\frac{1}{x}$ in this case (holds for all $x\neq0$). We can say that $-1\le\cos\frac{1}{x}\le1$. Multiplying this expression by $x^2$ maintains the validity as $x^2\ge0$ for all $x$, and hence $-x^2\le f(x)\le x^2$. Therefore $f(x)$ is bounded below by $-x^2$ and above by $x^2$ and $f(x)$ will converge to the limits of its bounds if they are equal. Taking the limits of the bounding functions gives us $\limit{x\to0}-x^2=0$ and $\limit{x\to0}x^2=0$. Since $f(x)$ is squeezed between $-x^2$ and $x^2$ as $x\to0$, $\limit{x\to0}-x^2\le \limit{x\to0} f(x)\le \limit{x\to0} x^2$. Hence by the squeeze theorem we have $\limit{x\to0} f(x)=0$ and thus $\limit{x\to0} x^2\cos\paren{\frac{1}{x}}=0$, as required.
\end{proof}

\noindent (d) $\limit{x\to0}\sin\paren{\frac{1}{x}}\cos\paren{\frac{1}{x}}$

\begin{proof}
	Note that individual components of the function $f(x)=\sin\paren{\frac{1}{x}}\cos\paren{\frac{1}{x}}$, $\sin\paren{\frac{1}{x}}$ and $\cos\paren{\frac{1}{x}}$ are both bounded by the interval $[-1,1]$. Note that the $f(x)$ and its components are discussed in this context with $x\neq0$. Therefore their product cannot exceed these bounds and hence we have that $-1\le\sin\paren{\frac{1}{x}}\cos\paren{\frac{1}{x}}\le1$, equivalently $-1\le f(c)\le 1$. Since $f(x)$ oscillates between -1 and 1, as those are its bounds due to the behavior of sine and cosine, $f(x)$ cannot converge to a limit. Hence $\limit{x\to0}\sin\paren{\frac{1}{x}}\cos\paren{\frac{1}{x}}$ does not exist, as required.
\end{proof}

\noindent (e) $\limit{x\to 0}\sin\paren{x}\cos\paren{\frac{1}{x}}$

\begin{proof}
	Let $f(x)=\sin\paren{x}\cos\paren{\frac{1}{x}}$. As per our argument in part (c), we know that  $\abs{\cos n}\le 1$ and hence $-1\le\cos\frac{1}{x}\le1$ for all $x\neq{0}$. This is acceptable as the function does not need to contain its limit, but it must approach it. To show this behavior, we multiply the previous expression by $\sin x$ to get an expression contending with $f(x)$. Thus we have $-\sin x\le\sin\paren{x}\cos\paren{\frac{1}{x}}\le\sin x$. This means that $f(x)$ is bounded below by $-\sin x$ and above by $\sin x$, and we can use the squeeze theorem as done in part (c) to prove convergence. Take the limits of the bounds to get $\limit{x\to0}-\sin x=0$ and $\limit{x\to0}\sin x$. This is known to be true as $\sin x$ is continuous and approaches 0 as $x$ approaches 0. Since $\sin\paren{x}\cos\paren{\frac{1}{x}}$ is squeezed by $-\sin x$ and $\sin x$, it must converge to their limits, which agree to be 0. Therefore, $\limit{x\to 0}\sin\paren{x}\cos\paren{\frac{1}{x}}=0$, as required.
\end{proof}

\newpage

% Begin Problem 5
\noindent \textbf{(3.1.2)} Prove \underline{Corollary 3.1.10}, that is, let $S\subset\bR$ and let $c$ be a cluster point of $S$. Suppose $f:S\to\bR$ is a function such that the limit of $f(x)$ as $x$ goes to $c$ exists. Suppose there are two real numbers $a$ and $b$ such that

\begin{align*}
	a\le f(x)\le b \qquad \text{for all }x\in S\setminus\set{c}
\end{align*}
\noindent Then
\begin{align*}
	a\le\limit{x\to c}f(x)\le b.
\end{align*}

\begin{proof}
	Let $L\coloneq \limit{x\to c}f(x)$ as it is given to exist. This means that for every $\epsilon>0$, there exists a $\delta>0$ such that $\abs{f(x)-L}<\epsilon$ whenever $\abs{x-c}<\delta$ for $x\in S\setminus\set{c}$. We want to show that given two real numbers $a,b$, with $a\le f(x)\le b$ for $x\in S\setminus\set{c}$, that $a\le L\le b$. We can express $\abs{f(x)-L}<\epsilon$ as $L-\epsilon<f(x)<L+\epsilon$ by the definition of the absolute value. We will break up this equality as $L-\epsilon<f(x)$ and $f(x)<L+\epsilon$ in order to better reach our end goal. Since $f(x)\le b$ is given, we have $L-\epsilon< f(x)\le b$ which is equivalent to $L-\epsilon\le b\implies L\le b+\epsilon$. Similarly for $a$, we are given that $a\le f(x)$ and hence $a\le f(x)<L+\epsilon$ which is equivalent to $a\le L+\epsilon\implies a-\epsilon\le L$. Note that in the previous derivations of the inequalities, we can choose $\le$ as a relation as limits allow for, but do not require, equality. We can recombine the inequalities $a-\epsilon\le L$ and $L\le b+\epsilon$ to yield $a-\epsilon\le L\le b+\epsilon$. Since $\epsilon>0$ is arbitrary, we can say generally that $a\le L\le b$, and hence $a\le\limit{x\to c}f(x)\le b$, as required.
\end{proof}

\end{document}
